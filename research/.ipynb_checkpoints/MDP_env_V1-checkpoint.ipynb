{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80di-0BctsAg"
   },
   "source": [
    "## Génération du Markov Decision Process\n",
    "\n",
    "### Définition du problème :\n",
    "\n",
    "Un agent se trouve sur une case aléatoire d'une grille 4 $\\times$ 4, sur la majorité des case de cette grille se trouvent des malus de score qui sont appliqués lorsqu'on marche dessus. Sur une faible fraction des cases se trouve un trésor, qui offre une récompense. Le but de l'agent est de maximiser sa récompense, en outre, il doit trouver le plus court chemin vers le trésor. Voici la grille des états :\n",
    "\n",
    "$$grid = \\begin{bmatrix}\n",
    "1 & 2 & 3 & 4 \\\\\n",
    "5 & 0 & 7 & 8 \\\\\n",
    "9 & 10 & 11 & 12 \\\\\n",
    "0 & 14 & 15 & 16 \n",
    "\\end{bmatrix}$$\n",
    "\n",
    "On remarque que certains états sont impossibles, il y a des obstacles dessus, ce qui est traduit par une étoile sur la case correspondante.\n",
    "\n",
    "D'après la définition du problème, la fonction de récompense ne dépend que de la case sur laquelle l'agent se déplace à un certain instant. On a donc $R:S\\to \\mathbb{R}$. Voici la matrice de récompense :\n",
    "$$R=\\begin{bmatrix}\n",
    "-0.1 & -0.1 & -0.1 & -0.1 \\\\\n",
    "- 1 & 0 & -0.1 & -0.1 \\\\\n",
    "-0.1 & -0.1 & -0.1 & -0.1 \\\\\n",
    "0 & 1 & -0.1 & -0.1\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Les actions que peut prendre l'agent sont des déplacements dans les 4 directions, cependant, ces actions ne sont pas déterministes, l'agent ne peut que \"essayer\" d'aller dans une direction. Toutefois, s'il essaie d'aller dans une direction, il n'est pas possible qu'il aille à l'opposé. Par exemple, si l'agent prend l'action \"essayer d'aller en haut\", il n'est pas possible qu'il aille en bas, par contre il peut aller à gauche ou à droite avec une probabilité faible.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Zbr6k5qSFmT"
   },
   "source": [
    "### Import des librairies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6LZanjzt6uf"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "23WLebUySLx8"
   },
   "source": [
    "### Définition des actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "De43ReqY7IdV"
   },
   "outputs": [],
   "source": [
    "## dans le sens des aiguilles d'une montre\n",
    "\n",
    "actions = {'up' : [0.8,0.1,0.,0.1], \n",
    "           'right':[0.1,0.8,0.1,0], \n",
    "           'down':[0.,0.1,0.8,0.1], \n",
    "           'left':[0.1,0.,0.1,0.8]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FT3RVJMfSQR6"
   },
   "source": [
    "### Définition de la matrice représentative de la grille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "grcI0sE2ROV7"
   },
   "outputs": [],
   "source": [
    "grid = np.array([[1,2,3,4],\n",
    "                 [5,0,7,8],\n",
    "                 [9,10,11,12],\n",
    "                 [0,14,15,16]]\n",
    "               )\n",
    "n_col = grid.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qq3D_Xl-SUqy"
   },
   "source": [
    "### Définition de la matrice d'adjacence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "FiQ5X0CiRPjS",
    "outputId": "03f3e87f-9921-46f2-de95-6f4fdc13e6ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "## cases numérotées de gauche à droite et de haut en bas\n",
    "\n",
    "n_states = np.prod(grid.shape)\n",
    "adj = np.zeros((n_states, n_states))\n",
    "\n",
    "for i in range (0, n_states) :\n",
    "    for j in range (0, n_states) :\n",
    "    # Si on est sur un état adjacent, et que cet état n'est pas obstrué, on met un 1 qui signifie qu'on peut aller sur cet état à partir\n",
    "    # de l'état où l'on est\n",
    "        if (j == i - n_col or j == i+1 or j == i + n_col or j == i-1) and grid[j//n_col,j%n_col]!=0 :\n",
    "            adj[i,j] = 1\n",
    "\n",
    "print(adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-PVru__9SXZa"
   },
   "source": [
    "Une fois que l'on a la matrice d'adjacence, les matrices de transitions ne sont que des déclinaisons de cette matrice.\n",
    "### Définition des matrices de transition\n",
    "\n",
    "On considère que quelque soit l'état, on peut essayer d'aller dans toutes les directions. Cependant, les matrices de transitions doivent être stochastiques donc on modifie leur contenu de sorte que la somme de chaque ligne vale 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yq-7Zn7LRha2",
    "outputId": "4533c462-9f06-43ba-aa7a-07859d3c432c"
   },
   "outputs": [],
   "source": [
    "T = []\n",
    "adj_coor = [-n_col, 1,n_col, -1]\n",
    "for action in actions :\n",
    "    Ta = np.zeros((n_states,n_states))\n",
    "    p = actions[action]\n",
    "    for i in range (0, n_states) :\n",
    "        for k in range(len(p)):\n",
    "            j = i+adj_coor[k]\n",
    "            if 0<=j<=15:\n",
    "                Ta[i, j] = adj[i, j]*p[k]\n",
    "                Lsum = np.sum(Ta[i,:])\n",
    "        if Lsum !=1:\n",
    "            Ta[i,:]*=1/Lsum\n",
    "    T.append(Ta)\n",
    "\n",
    "T = np.array(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 16, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.11111111 0.\n",
      " 0.         0.         0.         0.88888889]\n"
     ]
    }
   ],
   "source": [
    "print(T[2,11,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OQny11x1SuzG"
   },
   "source": [
    "### Définition des matrices de récompense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 62
    },
    "colab_type": "code",
    "id": "8Oy_GgTsRiDk",
    "outputId": "24fdd32f-f931-4acb-cec0-6d385ded3675"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1 -0.1 -0.1 -0.1 -1.   0.  -0.1 -0.1 -0.1 -0.1 -0.1 -0.1  0.   1.\n",
      " -0.1 -0.1]\n"
     ]
    }
   ],
   "source": [
    "R = np.array([-0.1, -0.1, -0.1, -0.1,\n",
    "              -1, 0, -0.1, -0.1,\n",
    "              -0.1, -0.1, -0.1, -0.1,\n",
    "              0, 1, -0.1,-0.1]).transpose()\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Autres rewards\n",
    "\n",
    "R2 = np.array([-0.4, -0.4, -0.4, -0.4,\n",
    "               -20, 0, -0.4, -0.4,\n",
    "               -0.4, -0.4, -0.4, -0.4,\n",
    "               0, 20, -0.4, -0.4]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithme de décision : Policy Iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre système est défini par un Markov Decision Process (matrice de transition T, matrice de récompense R, états S, ici matrice adjacence et grille).\n",
    "\n",
    "Nous cherchons la politique optimale avec l'algorithme de Policy Iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Utilisation de la toolbox MDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc : https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.11111111, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.88888889])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T[2,11,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 3, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mdptoolbox\n",
    "\n",
    "val_it = mdptoolbox.mdp.ValueIteration(T, R, 0.96)\n",
    "val_it.run()\n",
    "pol = val_it.policy\n",
    "pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 3, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tests sur les rewards\n",
    "\n",
    "val_it2 = mdptoolbox.mdp.ValueIteration(T, R2, 0.96)\n",
    "val_it2.run()\n",
    "val_it2.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T[2,15,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Algorithme codé à la main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Définition de l'agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "class Agent:\n",
    "    \n",
    "    def __init__(self, T, position, policy):\n",
    "        \n",
    "        self.T = T\n",
    "        self.policy = policy\n",
    "        self.position = position\n",
    "        self.history = []\n",
    "    \n",
    "    def goToNext(self):\n",
    "        \n",
    "        action_recommande = self.policy[self.position]\n",
    "        distribution_prochain_etat = self.T[action_recommande, self.position, :].tolist()\n",
    "        \n",
    "        probs, etats = [], []\n",
    "        \n",
    "        for j in range(len(distribution_prochain_etat)):\n",
    "            if distribution_prochain_etat[j] != 0:\n",
    "                probs.append(distribution_prochain_etat[j])\n",
    "                etats.append(j)\n",
    "        \n",
    "        # prochain_etat = np.random.choice(etats, 1, probs)\n",
    "        \n",
    "        custm = stats.rv_discrete(name=\"custm\", values=(etats, probs))\n",
    "        \n",
    "        prochain_etat = custm.rvs(size=1)\n",
    "        \n",
    "        self.history.append( (self.position, prochain_etat[0], action_recommande) )\n",
    "        self.position = prochain_etat[0]\n",
    "    \n",
    "        #print(\"nouvelle position: \", self.position)\n",
    "        \n",
    "    def getHistory(self):\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(T, 0, pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nouvelle position:  13\n"
     ]
    }
   ],
   "source": [
    "agent.goToNext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 0),\n",
       " (1, 2, 1),\n",
       " (2, 6, 2),\n",
       " (6, 10, 2),\n",
       " (10, 11, 2),\n",
       " (11, 15, 2),\n",
       " (15, 14, 2),\n",
       " (14, 13, 3)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.getHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def experiment_discount_factor(inf, sup, step, epochs):\n",
    "    \n",
    "    times = []\n",
    "    \n",
    "    for d in np.arange(inf, sup, step):\n",
    "        \n",
    "        \n",
    "        val_it = mdptoolbox.mdp.ValueIteration(T, R, 0.96)\n",
    "        val_it.run()\n",
    "        pol = val_it.policy\n",
    "        \n",
    "        time = []\n",
    "        for i in range(epochs):\n",
    "            agent = Agent(T, 0, pol)\n",
    "\n",
    "            while agent.position != 13:\n",
    "                agent.goToNext()\n",
    "                \n",
    "            time.append(len(agent.getHistory()))\n",
    "\n",
    "        times.append(np.mean(time))\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    x = np.arange(inf, sup, step)\n",
    "    y = times\n",
    "    plt.scatter(x,\n",
    "                y)\n",
    "    \n",
    "    z = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(x,p(x),\"r--\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment_discount_factor(0.1, 1, 0.01, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copie de MDP_V1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (data_science)",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
